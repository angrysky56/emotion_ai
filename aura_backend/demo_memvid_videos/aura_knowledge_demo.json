{
  "metadata": [
    {
      "id": 0,
      "text": "Advanced AI Companion Knowledge Base\n            ===================================\n            \n            Aura represents the next generation of AI companions, featuring:\n            \n            1. Emotional Intelligence System\n               - Real-time emotional state detection\n               - Brainwave pattern correlation (Alpha, Beta, Gamma, Theta, Delta)\n               - Neurotransmitter mapping (Dopamine, Serotonin, Oxytocin, GABA)\n               - 22+ distinct emotional states with mathematical formulas\n            \n            2. ASEKE Cognitive Framework\n               - KS: Knowledge Substrate - shared conversational context\n               - CE: Cognitive Energy - mental effort allocation\n               - IS: Information Structures - concept patterns\n               - KI: Knowledge Integration - learning processes\n               - KP: Knowledge Propagation - information sharing\n               - ESA: Emotional State Algorithms - emotional influence\n               - SDA: Sociobiologi",
      "frame": 0,
      "length": 1011
    },
    {
      "id": 1,
      "text": "- SDA: Sociobiological Drives - social dynamics\n            \n            3. Vector Memory System\n               - ChromaDB for semantic search\n               - Sentence transformer embeddings\n               - Persistent conversation memory\n               - Emotional pattern analysis\n            \n            4. Revolutionary Video Memory (Memvid Integration)\n               - QR-code compression technology\n               - Searchable MP4 video archives\n               - 10x storage efficiency\n               - Sub-second retrieval times\n               - H.264/H.265 compression support\n            \n            This combination creates an AI companion that remembers, learns,\n            and grows with each interaction while maintaining emotional awareness\n            and contextual understanding.",
      "frame": 1,
      "length": 801
    }
  ],
  "chunk_to_frame": {
    "0": 0,
    "1": 1
  },
  "frame_to_chunks": {
    "0": [
      0
    ],
    "1": [
      1
    ]
  },
  "config": {
    "qr": {
      "version": 35,
      "error_correction": "M",
      "box_size": 5,
      "border": 3,
      "fill_color": "black",
      "back_color": "white"
    },
    "codec": "h265",
    "chunking": {
      "chunk_size": 1024,
      "overlap": 32
    },
    "retrieval": {
      "top_k": 5,
      "batch_size": 100,
      "max_workers": 4,
      "cache_size": 1000
    },
    "embedding": {
      "model": "all-MiniLM-L6-v2",
      "dimension": 384
    },
    "index": {
      "type": "Flat",
      "nlist": 100
    },
    "llm": {
      "model": "gemini-2.0-flash-exp",
      "max_tokens": 8192,
      "temperature": 0.1,
      "context_window": 32000
    },
    "chat": {
      "max_history": 10,
      "context_chunks": 5
    },
    "performance": {
      "prefetch_frames": 50,
      "decode_timeout": 10
    }
  }
}